#!/bin/bash

source .env
source $ENV_INIT_SCRIPT_PATH/env_init.sh

echo "checking if ssh key pair exists or not..."

if  [ -r $AWS_SSH_KEYPATH ] && [ -r $AWS_SSH_KEYPATH.pub ]; then
	echo "ssh key pair exists, will use environment variable for AWS_SSH_KEYPATH, moving forward"
else
	echo "ssh key pair does not exist, hence will unset AWS_SSH_KEYPATH"
	echo "now ssh key pair will be generated by docker-machine itself"
	unset AWS_SSH_KEYPATH
	echo "AWS_SSH_KEYPATH unset, checking the value if still exists or not value=$AWS_SSH_KEYPATH"
fi


if [ "$#" -eq 1 ]; then
	export AWS_NODE_NAME="$1"
fi



# export CLUSTER_SIZE=5
# export MANAGER_COUNT=3
# export WORKER_COUNT=5
# export MACHINE_DRIVER=amazonec2
# export AWS_ACCESS_KEY_ID=<access_key_id>
# export AWS_SECRET_ACCESS_KEY=<secret_access_key>
# export AWS_DEFAULT_REGION=ap-south-1
# export AWS_AMI=ami-dd3442b2
# export AWS_VPC_ID=<aws_vpc_id>
# export AWS_SECURITY_GROUP=docker-machine
# export AWS_VOLUME_TYPE=gp2
# export AWS_SSH_USER=ubuntu
# export AWS_SSH_KEYPATH=<path/to/custom/ssh/private/key>
# export CREATE_SWARM=yes

# --amazonec2-subnet-id	AWS_SUBNET_ID	-
# --amazonec2-device-name	AWS_DEVICE_NAME	/dev/sda1
# --amazonec2-iam-instance-profile	AWS_INSTANCE_PROFILE	-
# --amazonec2-request-spot-instance	-	false
# --amazonec2-spot-price	-	0.50
# --amazonec2-use-private-address	-	false
# --amazonec2-private-address-only	-	false
# --amazonec2-monitoring	-	false
# --amazonec2-use-ebs-optimized-instance	-	false
# --amazonec2-retries	-	5


export MAIN_SWARM_MANAGER=${AWS_NODE_NAME}
echo "MAIN_SWARM_MANAGER : $MAIN_SWARM_MANAGER"
export MAIN_SWARM_MANAGER_NEW=no

export REMOVE="docker-machine rm --force -y "
export START="docker-machine start "
export STOP="docker-machine stop "
# export IP="docker-machine ip "


function create_node() {

	local CREATE="docker-machine create \
   		--amazonec2-zone $1 \
   		--amazonec2-tags $2 \
   		--amazonec2-instance-type $3 \
   		--amazonec2-root-size $4 \
   		--engine-label io.aroyd.machine.aws.region=$6 \
   		--engine-label io.aroyd.machine.aws.az=$7 \
   		--engine-label io.aroyd.machine.name=$8 \
   		$5"
   
   	# echo "CREATE : $CREATE"
   	# echo "creating node..."
   	$CREATE

}



function start_node() {

	$START $1  > /dev/null

}




function regenerate_certificates_docker() {
	docker-machine regenerate-certs --force $1 > /dev/null 
}



function aws_ec2_authorize_security_group_ingress_swarm() {
  
  aws ec2 authorize-security-group-ingress \
  --group-name "$AWS_SECURITY_GROUP" \
  --source-group "$AWS_SECURITY_GROUP" \
  --protocol $1 \
  --port $2  > /dev/null 2>&1 

}


function aws_ec2_authorize_security_group_ingress_internet() {
  
  aws ec2 authorize-security-group-ingress \
  --group-name "$AWS_SECURITY_GROUP" \
  --protocol $1 \
  --port $2 \
  --cidr $3 > /dev/null 2>&1 

}



function change_docker_env_to() {

	eval $(docker-machine env $1) > /dev/null
	if [ $? -ne 0 ]; then
		echo "Error in changing docker environment, regenerating certs..."
		docker-machine regenerate-certs --force $1
		eval $(docker-machine env $1) > /dev/null
	fi
}



function inspect_docker_node() {

	docker-machine ssh $1 sudo docker node inspect $2 > /dev/null 2>&1
}





# create a node
NODE_TYPE="$AWS_NODE_TYPE"
AWS_ZONE=${AWS_ZONE_NODE}
AWS_TAGS="Name,${AWS_NODE_NAME}"
AWS_INSTANCE_TYPE=${AWS_INSTANCE_TYPE_NODE}
AWS_ROOT_SIZE=${AWS_ROOT_SIZE_NODE}


# create the the swarm nodes
echo "[$AWS_NODE_NAME] - Checking if Node exists or not..."
docker-machine ls -q | grep -w "$AWS_NODE_NAME" > /dev/null 2>&1
if [ $? -ne 0 ];
then
	# create the swarm node
	# check if creating main master node too,
	# if yes, then mark it as newly creted/started
	# so that we will leave the earlier swarm forcefullly and 
	# update all nodes swarm configuration,
	# if not, then we will not do a forcefull swarm leave and rejoin
	if [ "$MAIN_SWARM_MANAGER" == "$AWS_NODE_NAME" ]; then
		MAIN_SWARM_MANAGER_NEW=yes
	fi
	echo "[$AWS_NODE_NAME] - creating  Node..."
	(
		create_node  "$AWS_ZONE"  "$AWS_TAGS"  "$AWS_INSTANCE_TYPE"  "$AWS_ROOT_SIZE"  "$AWS_NODE_NAME" "$AWS_DEFAULT_REGION" "$AWS_ZONE" "$AWS_NODE_NAME"
		echo "[$AWS_NODE_NAME] - Node created"
	) &

else
	echo "[$AWS_NODE_NAME] - Node already exists"
	echo "[$AWS_NODE_NAME] - checking Node status, start if currently stopped, otherwise move forward"
	
	docker-machine status "$AWS_NODE_NAME" | grep -w "Stopped" > /dev/null 2>&1
	if [ $? -eq 0 ];
	then
		# start the stopped cluster node machine
		# check if creating main master node too,
		# if yes, then mark it as newly creted/started
		# so that we will leave the earlier swarm forcefullly and 
		# update all nodes swarm configuration,
		# if not, then we will not do a forcefull swarm leave and rejoin
		if [ "$MAIN_SWARM_MANAGER" == "$AWS_NODE_NAME" ]; then
			MAIN_SWARM_MANAGER_NEW=yes
		fi
		echo "[$AWS_NODE_NAME] machine is Stopped, hence starting..."
		(
			start_node "$AWS_NODE_NAME"
			echo "[$AWS_NODE_NAME] machine started Successfully"
		) &

	else
		echo "[$AWS_NODE_NAME] machine is already running, moving forward"
	fi
	
fi


echo "Wating for node creation..."
wait
echo "Node Created"

# list the cluster machines
echo "Current Docker Hosts:"
docker-machine ls


# update the security group for ssl traffic
echo "[$AWS_SECURITY_GROUP] Updating security group for Internet"
echo "Updating security group for TCP Ports"
for port in "${OPEN_PORTS_TCP_INTERNET[@]}"; do
	echo "Opening tcp port : $port.."
	(
		aws_ec2_authorize_security_group_ingress_internet tcp "$port" 0.0.0.0/0
		echo "tcp port $port opened successfully"
	) &
done
echo "Updating security group for UDP Ports"
for port in "${OPEN_PORTS_UDP_INTERNET[@]}"; do
	echo "Opening udp port : $port.."
	(
		aws_ec2_authorize_security_group_ingress_internet udp "$port" 0.0.0.0/0
		echo "udp port $port opened successfully"
	) &
done



echo "Wating for opening tcp and udp ports for internet..."
wait
echo "Security Group Udpated for Internet"



echo "Checking if node to be creted inside a swarm to be created or not..."
# proceed with swarm creation only if necesssary
if [ "$SWARM_MODE_NODE" == "yes" ]; then

	echo "Swarm Creation Starting..."
	echo "Updating security group $AWS_SECURITY_GROUP for swarm"
	##############
	### NOTE: ###
	##############
	# The following ports must be available. On some systems, these ports are open by default.
	# 
	# TCP port 2377 for cluster management communications
	# TCP and UDP port 7946 for communication among nodes
	# TCP and UDP port 4789 for overlay network traffic
	# 
	# If you are planning on creating an overlay network with encryption (--opt encrypted), 
	# you will also need to ensure ip protocol 50 (ESP) traffic is allowed.


	################################################################################################
	# update the security group docker-machine or whatever is given 
	# to open connections for docker swam since the docker-machine as of now (January, 2017)
	# is unable to create the necessary security group rules automatically
	echo "Updating security group for TCP Ports"
	for port in "${OPEN_PORTS_TCP_SWARM[@]}"; do
		echo "opening tcp port internally port : $port.."
		(
			aws_ec2_authorize_security_group_ingress_swarm tcp "$port"
			echo "tcp port $port opened internally successfully"
		) &
	done
	echo "Updating security group for UDP Ports"
	for port in "${OPEN_PORTS_UDP_SWARM[@]}"; do
		echo "opening udp port internally port : $port.."
		(
			aws_ec2_authorize_security_group_ingress_swarm udp "$port"
			echo "udp port $port opened internally successfully"
		) &
	done

	echo "Wating for opening tcp and udp ports for swarm..."
	wait
	echo "Security Group Udpated for Swarm"

	echo "Checing if swarm node to be initialized or not"
	if [ "$CREATE_SWARM_NODE" == "yes" ]; then
		export MAIN_SWARM_MANAGER=${AWS_NODE_NAME}
		echo "MAIN_SWARM_MANAGER : $MAIN_SWARM_MANAGER"
		export MAIN_SWARM_MANAGER_PRIVATE_IP=$(docker-machine inspect "$MAIN_SWARM_MANAGER" --format '{{json .Driver.PrivateIPAddress}}')
		echo "Main Swarm Manager Private IP : $MAIN_SWARM_MANAGER_PRIVATE_IP"

		# init swarm (need for service command); if not created
		echo "Checking if Swarm is needs to be initialized or not"
		if [ "$MAIN_SWARM_MANAGER_NEW" == "yes" ]; then
			echo "Main Swarm Manger Node has been created/started, hence new ip, thus reinitialzing swarm"
			echo "First leaving previous swarm, if any"
			docker-machine ssh "$MAIN_SWARM_MANAGER" <<- EOSSH
				sudo docker swarm leave --force > /dev/null 2>&1
				echo "Initializing new swarm..."
				sudo docker swarm init --advertise-addr "$MAIN_SWARM_MANAGER_PRIVATE_IP" > /dev/null 
				echo "Swarm Initialized"
				echo "Adding Labels to Node"
				sudo docker node update --label-add io.aroyd.swarm.cluster.node.aws.region="$AWS_DEFAULT_REGION" \
	   			--label-add io.aroyd.swarm.cluster.node.aws.az="$AWS_ZONE" \
	   			--label-add io.aroyd.swarm.cluster.node.name="$MAIN_SWARM_MANAGER" \
	   			"$MAIN_SWARM_MANAGER"
	   			echo "Labels Added"
			EOSSH
		else 
			# initialize swarm only if it is already not initialzed
			echo "Main Swarm Manager has not been creted or restarded, hence now checking if swarm is already initialzed or not.."
			docker-machine ssh "$MAIN_SWARM_MANAGER" <<- EOSSH
				sudo docker node ls > /dev/null 2>&1 | grep "Leader" > /dev/null 2>&1
				if [ $? -ne 0 ]; 
				then
					# initialize swarm mode
					echo "Swarm not initialzed, hence starting..."
					echo "Initializing Swarm..."
					sudo docker swarm init --advertise-addr "$MAIN_SWARM_MANAGER_PRIVATE_IP" > /dev/null
					echo "Swarm Initialized"
					echo "Adding Labels to Node"
					sudo docker node update --label-add io.aroyd.swarm.cluster.node.aws.region="$AWS_DEFAULT_REGION" \
		   			--label-add io.aroyd.swarm.cluster.node.aws.az="$AWS_ZONE" \
		   			--label-add io.aroyd.swarm.cluster.node.name="$MAIN_SWARM_MANAGER" \
		   			"$MAIN_SWARM_MANAGER"
		   			echo "Labels Added"
				else
					echo "Swarm already initailized, moving forward"
				fi
			EOSSH
		fi

	else 
		echo "Checking if the the node is initialzed to swarm, if yes, \
		move forward, else join the swarm either as manager or worker as mentioned in config"	

		echo "MAIN_SWARM_MANAGER : $MAIN_SWARM_MANAGER"
		export MAIN_SWARM_MANAGER_PRIVATE_IP=$(docker-machine inspect "$MAIN_SWARM_MANAGER" --format '{{json .Driver.PrivateIPAddress}}')
		echo "Main Swarm Manager Private IP : $MAIN_SWARM_MANAGER_PRIVATE_IP"


		SWARM_JOIN_TOKEN=$AWS_SWARM_TOKEN

		echo "[$AWS_NODE_NAME] - Inspecting..."
		(
			
			echo "$AWS_NODE_NAME node joining swarm mananger..."
			# first leave any previous swarm if at all
			docker-machine ssh "$AWS_NODE_NAME" <<- EOSSH
				sudo docker swarm leave --force > /dev/null 2>&1
				sudo docker swarm join --token  "$SWARM_JOIN_TOKEN"  "$MAIN_SWARM_MANAGER_PRIVATE_IP":2377 > /dev/null
				echo "$AWS_NODE_NAME joined swarm manager"
			EOSSH

			echo "[$AWS_NODE_NAME] - Adding Labels to Node" 
			docker-machine ssh "$MAIN_SWARM_MANAGER" <<- EOSSH
				sudo docker node update --label-add io.aroyd.swarm.cluster.node.aws.region="$AWS_DEFAULT_REGION" \
	   				--label-add io.aroyd.swarm.cluster.node.aws.az="$AWS_ZONE" \
	   				--label-add io.aroyd.swarm.cluster.node.name="$AWS_NODE_NAME" \
	   			"$AWS_NODE_NAME"

	   		EOSSH
	   		
	   		echo "[$AWS_NODE_NAME] - Labels Added"
		
		) &


		echo "Wating for swarm creation..."
		wait
		echo "Swarm Nodes Initialization completed"

	fi

else 

	echo "Swarm Creation Not Required, moving forward"
fi


if [ "$CONFIGURATION" == "yes" ]; then

	echo "Configuring Each Node..."
	# install docker-compose in each node
	echo "[$AWS_NODE_NAME] - processing for swarm node..."
	(
		docker-machine ssh "$AWS_NODE_NAME"  <<- EOSSH
			if ! which docker-compose > /dev/null 2>&1; then 
				echo "[$AWS_NODE_NAME] - Installing docker-compose..."
				sudo curl -L "https://github.com/docker/compose/releases/download/1.10.0/docker-compose-$(uname -s)-$(uname -m)" \
				-o /usr/local/bin/docker-compose > /dev/null 
				sudo chmod +x /usr/local/bin/docker-compose 
			else
				echo "[$AWS_NODE_NAME] - docker-compose already installed, moving forward"
			fi

			echo "[$AWS_NODE_NAME] - adding user ubuntu to group docker"
			sudo usermod -aG docker ubuntu > /dev/null
			if [ $? -ne 0 ]; then 
				echo "[$AWS_NODE_NAME] - user ubuntu unable to be added to group docker"
			else
				echo "[$AWS_NODE_NAME] - user ubuntu added to group docker successfully"
			fi

			if ! which rexray > /dev/null 2>&1; then 
				echo "[$AWS_NODE_NAME] - Installing Rex-Ray"
				curl -sSL https://dl.bintray.com/emccode/rexray/install | sh
				echo "[$AWS_NODE_NAME] - Rex-Ray Installed"
				
			else
				echo "[$AWS_NODE_NAME] - Rex-Ray Already INstalled, moving forward"
			fi
		
		EOSSH

		echo "[$AWS_NODE_NAME] - Configuring Rex-Ray"
		docker-machine ssh "$AWS_NODE_NAME"  sudo tee /etc/rexray/config.yml < "$STORAGE_PROVISION_CONFIG_FILE" > /dev/null
		echo "[$AWS_NODE_NAME] - Rex-Ray configured"
		echo "[$AWS_NODE_NAME] - Rex-Ray Restarting"
		docker-machine ssh "$AWS_NODE_NAME" sudo rexray start > /dev/null
		echo "[$AWS_NODE_NAME] - Rex-Ray Restarted Successfully"

		echo "[$AWS_NODE_NAME] - processing done"

	) &


	echo "Wating for configuration of nodes..."
	wait
	echo "configuration of all nodes completed"

else
	echo "Configuration not required, moving forward"
fi


echo "Provisioning Successful"
